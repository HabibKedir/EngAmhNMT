# -*- coding: utf-8 -*-
"""EngAmhRnnKf.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1krBMqnUNOJ-4BRDdGmg5FZnE5mRP66l7

Python Code Implementation
"""

# Import necessary libraries
import os

def remove_long_sentences(file_path, output_path, max_tokens=60):
    """
    Reads a file, removes lines with more than the specified number of tokens, and writes the result to a new file.

    :param file_path: Path to the input text file
    :param output_path: Path to save the output text file
    :param max_tokens: Maximum number of tokens allowed in a sentence
    """
    with open(file_path, 'r', encoding='utf-8') as file:
        lines = file.readlines()

    # Process each line
    filtered_lines = []
    for line in lines:
        tokens = line.strip().split()  # Tokenize the line by splitting on spaces
        if len(tokens) <= max_tokens:
            filtered_lines.append(line)

    # Write the filtered lines to the output file
    with open(output_path, 'w', encoding='utf-8') as file:
        file.writelines(filtered_lines)

    print(f"Filtered sentences saved to {output_path}.")
    print(f"Total sentences removed: {len(lines) - len(filtered_lines)}")
    print(f"Remaining sentences: {len(filtered_lines)}")


# Input file path
input_file = "/content/drive/MyDrive/New/Eng-Amh.txt"
# Output file path
output_file = "/content/drive/MyDrive/New/filtered_Eng-Amh.txt"

# Run the function
remove_long_sentences(input_file, output_file, max_tokens=60)